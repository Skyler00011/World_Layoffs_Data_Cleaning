# World Layoffs Data Cleaning Project  

## Overview  
This project focuses on cleaning and optimizing a worldwide layoffs dataset using SQL. We transform raw data into a structured and reliable format by addressing inconsistencies, duplicates, and missing values, making it more suitable for analysis.  

## Data Source  
- Dataset: CSV file containing worldwide layoff data  
- Contents: Company names, industries, locations, number of layoffs, total workforce, and layoff dates  

## Project Workflow  
1. Data Acquisition: Imported the CSV file into SQL.  
2. Data Cleaning (SQL):  
   - Identified and removed duplicate records.  
   - Standardized column formats (e.g., date, numerical values, and text consistency).  
   - Handled missing values appropriately.  
   - Optimized data types for efficiency.  
3. Data Optimization:  
   - Indexed relevant columns for faster querying.  
   - Ensured referential integrity where applicable.  
   - Created a structured and organized version of the dataset for analysis.  

## Key Improvements  
- Removed redundant and inconsistent data.  
- Standardized formats for better readability and usability.  
- Improved query performance with optimized indexing.  
- Enhanced dataset accuracy for further analysis.  

## Tools Used  
- SQL: Data cleaning, transformation, and optimization.  

## Conclusion  
This project improves the quality and usability of worldwide layoff data, ensuring it is structured and efficient for deeper analysis. The cleaned dataset can be used to identify trends, industry impacts, and historical comparisons.  

